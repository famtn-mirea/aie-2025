# HW06 – Report

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000, 62)
- Целевая переменная: `target` (Классы 0 и 1, содержащие соответственно 23770 и 1230 образцов)
- Признаки: числовые

## 2. Protocol

- Разбиение: 80/20, random_state=42
- Подбор: 5 фолдов, оптимизация f1-меры
- Метрики: accuracy, precision, recall, F1, ROC-AUC, PR-AUC. Accuracy не может использоваться в одиночестве, так как данные не сбалансированы. Precision и Recall позволяют отслеживать, какой ценой происходит увеличение f1 меры (ухудшается ли при этом способность модели выявлять 0 класс). ROC-AUC и PR-AUC используются также для оценки качества модели одним числом с учётом дисбаланса.

## 3. Models

- DummyClassifier - подбираемые параметры: {'strategy': ['prior', 'stratified', 'uniform', 'constant']}
- LogisticRegression - подбираемые параметры: {'class_weight': ['balanced', {0: 1.0, 1: 5.0}, {0: 1.0, 1: 25.0}, {0: 1.0, 1: 100.0}]}
- DecisionTreeClassifier - подбираемые параметры {'max_depth': [5, 15, None], 'min_samples_leaf': [1, 3, 5, 10], 'class_weight': ['balanced', {0: 1.0, 1: 5.0}]}
- RandomForestClassifier - подбираемые параметры  {'n_estimators': [50, 100, 300], 'max_features': ['sqrt', 15, 25]}
- GradientBoosting - подбираемые параметры {'learning_rate': [1.0, 0.1, 0.001, 0.01], 'max_depth': [1, 2, 3]}

## 4. Results

- DummyClassifier:
    "accuracy": 0.0492,
    "precision": 0.0492,
    "recall": 1.0,
    "f1": 0.09378574151734655,
    "pr-auc": 0.0492,
    "roc-auc": 0.5
  
- LogisticRegression
    "accuracy": 0.9444,
    "precision": 0.4389312977099237,
    "recall": 0.46747967479674796,
    "f1": 0.452755905511811,
    "pr-auc": 0.4885700573912299,
    "roc-auc": 0.8374710556108506
  
- DecisionTreeClassifier
    "accuracy": 0.9534,
    "precision": 0.5269709543568465,
    "recall": 0.516260162601626,
    "f1": 0.5215605749486653,
    "pr-auc": 0.2724642099161356,
    "roc-auc": 0.6703097263408477

- RandomForestClassifier
    "accuracy": 0.9732,
    "precision": 0.9827586206896551,
    "recall": 0.4634146341463415,
    "f1": 0.6298342541436464,
    "pr-auc": 0.7691681739101286,
    "roc-auc": 0.8990943869261999

- GradientBoosting
    "accuracy": 0.9758,
    "precision": 0.8654970760233918,
    "recall": 0.6016260162601627,
    "f1": 0.709832134292566,
    "pr-auc": 0.7151652684408367,
    "roc-auc": 0.8978985603907363

  Лучшей моделью признаем градиентный бустинг, т.к. разница между ним и случайным лесом в ROC-AUC и PR-AUC не столь значительна, а вот f1 заметно больше (модель лучше справляется с обнаружением меньшего класса)

## 5. Analysis

- Была проведена проверка на устойчивость для случайного леса. Дя random_state от 43 до 46 включительно f1 оказывался в диапозоне от 0.58 до 0.63, что близко к полученному в экмперименте результату.
- Confusion matrix градиентного бустинга:
  [4731   23]
  [98    148]
- Топ 10 признаков:
  f53
  f25
  f04
  f33
  f47
  f58
  f08
  f38
  f54
  f13
  Отсутствие информации о том, что именно значат эти признаки не даёт сделать юолее точные выводы.

## 6. Conclusion

Модели на основе ансамблей показывают лучшие результаты в задачах с сильным дисбалансом классов. При определении веса классов для моделей не всегда оптимальным будет вариант, отражающий реальное соотношение. Случайный лес не требует контроля глубины отдельных деревьев (устойчивость к переобучению).
