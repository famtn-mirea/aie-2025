# HW07 – Report


## 1. Datasets

Выбрали 3 датасета из 4:

### 1.1 Dataset A

- Файл: 'S07-hw-dataset-01.csv'
- Размер: (12000, 9)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разный масштаб признаков

### 1.2 Dataset B

- Файл: 'S07-hw-dataset-02.csv'
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет 
- "Подлости" датасета: один из трёх признаков находится в очень большом диапозоне, в сравнении с остальными

### 1.3 Dataset C

- Файл: 'S07-hw-dataset-03.csv'
- Размер: (15000, 4)
- Признаки: числовые
- Пропуски: нет 
- "Подлости" датасета: нет

## 2. Protocol

- Препроцессинг: scaling
- Поиск гиперпараметров:
  - Для K-means: от 2 до 20 включительно
  - Для аггломеративной кластеризации: выбор между complete и ward в качестве linkage
  - В качестве критерия выбора использовался silhouette
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)

## 3. Models

Для первого датасета:
- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- AgglomerativeClustering (`k` подбирали на основе дендрограммы, `linkage` искали, фиксировали `random_state`)

Для второго датасета:
- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- AgglomerativeClustering (`k` подбирали на основе дендрограммы, `linkage` искали, фиксировали `random_state`)

Для третьего датасета:
- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- AgglomerativeClustering (`k` подбирали на основе дендрограммы, `linkage` искали, фиксировали `random_state`)

## 4. Results

### 4.1 Dataset A

- Лучший метод: KMeans с двумя кластерами
- Метрики: sil_score = 0.5216395622404242, db_score = 0.6853295219054457, ch_score= 11786.954622671532
- Решение показало результат в точности равный методу AgglomerativeClustering (в котором также выделяли два кластера)

### 4.2 Dataset B

- Лучший метод: KMeans с двумя кластерами
- Метрики: sil_score = 0.3068610017701601, db_score = 1.3234721699867644, ch_score = 3573.3933329348392
- Решение показало результат выше метода AgglomerativeClustering

### 4.3 Dataset C

- Лучший метод: KMeans с двумя кластерами
- Метрики: sil_score = 0.31553248183109267, db_score = 1.1577832240211112, ch_score = 6957.158106946779
- Решение показало результат выше метода AgglomerativeClustering

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans всегда показал наилучший результат в сравнение с аггломеративной кластеризацией (с проверкой двух типов linkage)
- После снижения размерности методом PCA кластеры действительно оказались чётко отделимы друг ои друга

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проводилась на первом датасете, KMeans был запущен 5 раз с разным random_seed.
- Все результаты оказались одинаковыми, ARI между каждой парой равен 1
- Вывод: устойчиво, исходные данные явно различимы.

### 5.3 Интерпретация кластеров

- Не проводилось

## 6. Conclusion

Научились проводить кластеризацию двумя методами с подбором оптимального количества кластеров гоафическими методами. Использовать метрики оценки точности кластеризации при отсутствии истинных меток. Проверять устойчивость результатов кластеризации с помощью ARI
